{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from numpy import concatenate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "filePath = 'data-normalized/'\n",
    "fileCount = 0\n",
    "scanData = []\n",
    "scanNP_list =[]\n",
    "\n",
    "yList = []\n",
    "vve = pd.read_csv(\"VVE-clinical-devset.csv\")\n",
    "for index, row in vve.iterrows():\n",
    "    fileName = row['ScanFileName']\n",
    "    fnLen = len(fileName)\n",
    "    modFileName = fileName[0:fnLen-4] + \"_norm.csv\"\n",
    "    scanFile = filePath + modFileName\n",
    "    if path.exists(scanFile):      \n",
    "        yList.append(row['VVE_NumMeasuresAbnormal'])\n",
    "        #dataframeY = dataframeY.append({'VVEScore':row['VVE_NumMeasureAbnormal']})\n",
    "        fileCount += 1\n",
    "        scanContents = pd.read_csv(scanFile)\n",
    "        scanNP = scanContents.to_numpy()\n",
    "        scanData.append(scanContents)  \n",
    "        scanNP_list.append(scanNP)\n",
    "        dfx = pd.DataFrame(scanNP)\n",
    "        dfy = dfx.apply(lambda x: x.str.strip() if isinstance(x, str) else x).replace('', np.nan)\n",
    "        df = df.append({'patient#': modFileName, 'LeftX': dfy[1], 'LeftY': dfy[2], 'LeftVelX': dfy[3], 'LeftVelY': dfy[4], 'RightX': dfy[5], \n",
    "                        'RightY': dfy[6], 'RightVelX': dfy[7], 'RightVelY': dfy[8], 'LeftPupilRadius': dfy[9], \n",
    "                        'RightPupilRadius': dfy[10], \"LeftRadialVel\": dfy[11], 'LeftRadialAcc': dfy[12], \n",
    "                        'LeftRadialJerk': dfy[13], 'RightRadialVel': dfy[14], \n",
    "                        'RightRadialAcc': dfy[15], 'RightRadialJerk': dfy[16]}, ignore_index=True)\n",
    "    else:\n",
    "       print(scanFile)\n",
    "\n",
    "        #display(dfy)\n",
    "        #if scanContents['LeftX'].notnull().values.sum() < 1000:\n",
    "          #print(scanFile + '\\n')\n",
    "\n",
    "display(df)\n",
    "print(fileCount)\n",
    "\n",
    "print(index)\n",
    "print(yList)\n",
    "#train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "#display(train)\n",
    "\n",
    "#print(str(fileCount) + ' datafiles found.')\n",
    "#print(scanData)\n",
    "#scanArray = np.dstack(scanNP_list)\n",
    "#np.save(filePath + 'scanArray', scanArray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_count = len(data)\n",
    "rec_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(X, y, sequence_length = 10, step = 1):\n",
    "    X_local = []\n",
    "    y_local = []\n",
    "    for start in range(0, len(data) - sequence_length, step):\n",
    "        end = start + sequence_length\n",
    "        X_local.append(X[start:end])\n",
    "        y_local.append(y[end-1])\n",
    "    return np.array(X_local), np.array(y_local)\n",
    "\n",
    "X_sequence, y = generate_data(data.loc[:, \"V1\":\"V28\"].values, data.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(LSTM(100, input_shape = (10, 28)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\"\n",
    "              , metrics=[keras.metrics.binary_accuracy]\n",
    "              , optimizer=\"adam\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = int(len(X_sequence) * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_sequence[:training_size], y[:training_size]\n",
    "X_test, y_test = X_sequence[training_size:], y[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.where(y_test_prob > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d225f7354b000a0ce395f9e71d4e065934dd574a69e7052fba0a00de66e59672"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
